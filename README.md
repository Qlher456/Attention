# Attention

# CNN.py
CNN.py是使用基础cnn网络在Cifar10数据集上迭代100次的文件

使用ACC评价标准和交叉熵损失函数

batch_size = 64

learning_rate = 0.001

Epoch [1/100] Train Loss: 1.5441, Train Acc: 43.86% Test Loss: 1.1843, Test Acc: 58.41%

Epoch [10/100] Train Loss: 0.6759, Train Acc: 76.03% Test Loss: 0.7941, Test Acc: 72.85%

Epoch [20/100] Train Loss: 0.4526, Train Acc: 83.17% Test Loss: 0.9331, Test Acc: 72.84%

Epoch [30/100] Train Loss: 0.3581, Train Acc: 86.36% Test Loss: 1.0677, Test Acc: 72.81%

Epoch [40/100] Train Loss: 0.3025, Train Acc: 88.26% Test Loss: 1.3608, Test Acc: 73.02%

Epoch [50/100] Train Loss: 0.2704, Train Acc: 89.42% Test Loss: 1.5004, Test Acc: 72.53%

Epoch [60/100] Train Loss: 0.2449, Train Acc: 90.36% Test Loss: 1.5833, Test Acc: 72.55%

Epoch [70/100] Train Loss: 0.2346, Train Acc: 90.76% Test Loss: 1.6706, Test Acc: 72.87%

Epoch [80/100] Train Loss: 0.2216, Train Acc: 91.34% Test Loss: 1.8683, Test Acc: 72.17%

Epoch [90/100] Train Loss: 0.2058, Train Acc: 91.91% Test Loss: 1.8556, Test Acc: 71.97%

Epoch [100/100] Train Loss: 0.1969, Train Acc: 92.28% Test Loss: 1.9651, Test Acc: 72.11%

![training_plot](https://github.com/user-attachments/assets/241774b2-29a6-4410-b49a-108931424047)


# Self-Attention.py

Self-Attention.py是在基础cnn网络中引入自注意力机制在Cifar10数据集上迭代100次的文件

训练环境同上

Epoch [1/100] Train Loss: 1.5294, Train Acc: 44.27% Test Loss: 1.1464, Test Acc: 58.42%

Epoch [10/100] Train Loss: 0.3852, Train Acc: 86.20% Test Loss: 0.7361, Test Acc: 77.08%

Epoch [20/100] Train Loss: 0.2026, Train Acc: 92.67% Test Loss: 0.9745, Test Acc: 77.55%

Epoch [30/100] Train Loss: 0.1569, Train Acc: 94.39% Test Loss: 1.2330, Test Acc: 76.77%

Epoch [40/100] Train Loss: 0.1439, Train Acc: 95.04% Test Loss: 1.5118, Test Acc: 75.73%

Epoch [50/100] Train Loss: 0.1224, Train Acc: 95.81% Test Loss: 1.4674, Test Acc: 76.74%

Epoch [60/100] Train Loss: 0.1187, Train Acc: 95.91% Test Loss: 1.5973, Test Acc: 76.51%

Epoch [70/100] Train Loss: 0.1163, Train Acc: 96.02% Test Loss: 1.6436, Test Acc: 77.22%

Epoch [80/100] Train Loss: 0.1047, Train Acc: 96.54% Test Loss: 1.7462, Test Acc: 76.69%

Epoch [90/100] Train Loss: 0.0980, Train Acc: 96.72% Test Loss: 1.7892, Test Acc: 76.37%

Epoch [100/100] Train Loss: 0.0909, Train Acc: 97.05% Test Loss: 1.7741, Test Acc: 77.09%

![image](https://github.com/user-attachments/assets/f2951def-11aa-4867-8632-da7b48b81165)

# Multi-Head Attention.py


